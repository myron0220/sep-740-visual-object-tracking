{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e939053",
   "metadata": {},
   "source": [
    "![]('Screenshot 2023-07-25 at 18.15.20.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe136ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO # calling the kernal\n",
    "import cv2 # cv2 c++\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort # tracker in c++\n",
    "\n",
    "import datetime\n",
    "\n",
    "# from helper import create_video_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca38d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_directory: \n",
      "/Users/kidsama/Documents/Current_Courses/SEP 740/assignment&project/final_project/sep-740-visual-object-tracking/researches\n",
      "\n",
      "files: \n",
      "['Untitled1.ipynb', 'Untitled.ipynb', 'demo.ipynb', '.ipynb_checkpoints', 'deepsort.pdf', 'kalman_filter.png']\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "files = os.listdir(current_directory)\n",
    "\n",
    "print('current_directory: ')\n",
    "print(current_directory)\n",
    "print()\n",
    "print('files: ')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed09a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_video_writer(video_cap, output_filename):\n",
    "\n",
    "    # grab the width, height, and fps of the frames in the video stream.\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # initialize the FourCC and a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n",
    "                             (frame_width, frame_height))\n",
    "\n",
    "    return writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62581d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"test.mp4\"\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
      "100%|██████████████████████████████████████| 6.23M/6.23M [00:00<00:00, 64.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.8\n",
    "GREEN = (0, 255, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "# initialize the video capture object\n",
    "video_cap = cv2.VideoCapture(\"test.mp4\")\n",
    "# initialize the video writer object\n",
    "writer = create_video_writer(video_cap, \"output.mp4\")\n",
    "\n",
    "# load the pre-trained YOLOv8n model\n",
    "model = YOLO(\"yolov8n.pt\") # object detection (frame) -> \n",
    "tracker = DeepSort(max_age=50) # object trajectory & kalman_filter -> tracker\n",
    "\n",
    "\n",
    "while True:\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    ret, frame = video_cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # run the YOLO model on the frame\n",
    "    detections = model(frame)[0]\n",
    "\n",
    "    # initialize the list of bounding boxes and confidences\n",
    "    results = []\n",
    "\n",
    "    ######################################\n",
    "    # DETECTION\n",
    "    ######################################\n",
    "\n",
    "    # loop over the detections\n",
    "    for data in detections.boxes.data.tolist():\n",
    "        print(\"--- data ---\")\n",
    "        print(data)\n",
    "        print(\"--- ---- ---\")\n",
    "      \n",
    "        # extract the confidence (i.e., probability) associated with the prediction\n",
    "        confidence = data[4]\n",
    "\n",
    "        # filter out weak detections by ensuring the \n",
    "        # confidence is greater than the minimum confidence\n",
    "        if float(confidence) < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        # if the confidence is greater than the minimum confidence,\n",
    "        # get the bounding box and the class id\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        class_id = int(data[5])\n",
    "        # add the bounding box (x, y, w, h), confidence and class id to the results list\n",
    "        results.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "    ######################################\n",
    "    # TRACKING\n",
    "    ######################################\n",
    "\n",
    "    # update the tracker with the new detections\n",
    "    tracks = tracker.update_tracks(results, frame=frame)\n",
    "    # loop over the tracks\n",
    "    for track in tracks:\n",
    "        # if the track is not confirmed, ignore it\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        # get the track id and the bounding box\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "\n",
    "        xmin, ymin, xmax, ymax = int(ltrb[0]), int(\n",
    "            ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "        # draw the bounding box and the track id\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.rectangle(frame, (xmin, ymin - 20), (xmin + 20, ymin), GREEN, -1)\n",
    "        cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, 2)\n",
    "\n",
    "    # end time to compute the fps\n",
    "    end = datetime.datetime.now()\n",
    "    # show the time it took to process 1 frame\n",
    "    print(f\"Time to process 1 frame: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "    # calculate the frame per second and draw it on the frame\n",
    "    fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    writer.write(frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "video_cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56055315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root",
   "language": "python",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
